{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "recovered-password",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "from abc import ABC\n",
    "import pickle\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from typing import List\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "EMB = r\"C:\\Users\\Wilk\\PiSR1\\data\\emb.p\"\n",
    "RATINGS_SMALL = r\"C:\\Users\\Wilk\\PiSR1\\data\\ratings_small.csv\"\n",
    "SEED = 42\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "featured-tackle",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_csv(RATINGS_SMALL)\n",
    "movies_emb = pickle.load( open( EMB, \"rb\" ) )\n",
    "dataset = ratings.merge(movies_emb[['id', 'title','overview',\"vector\"]], left_on='movieId', right_on='id')\n",
    "dataset = dataset.set_index(\"id\")\n",
    "dataset.userId = dataset.userId.astype(\"Int64\")\n",
    "target = dataset.rating.to_numpy()\n",
    "\n",
    "dataset = dataset.drop([\"timestamp\",\"title\",\"overview\",\"movieId\",\"rating\"],axis=1).to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "domestic-resource",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensors = []\n",
    "for data in dataset:\n",
    "    x = torch.FloatTensor(np.append(data[0],data[1]))\n",
    "    tensors.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "proved-dealing",
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAT_SIZE = 768+1\n",
    "OUTPUT = 1\n",
    "BATCH_SIZE = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "boring-fitness",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContentBaseRecommenderSystem(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_feature_size):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_feature_size) #fully connected    \n",
    "        self.fc2 = nn.Linear(hidden_feature_size, hidden_feature_size)\n",
    "        self.fc3 = nn.Linear(hidden_feature_size, hidden_feature_size)\n",
    "        self.out_layer = nn.Linear(hidden_feature_size, 1)\n",
    "        self.act_fn = F.relu\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.act_fn(self.fc1(x))\n",
    "        x = self.act_fn(self.fc2(x))\n",
    "        x = self.act_fn(self.fc3(x))\n",
    "        out = self.out_layer(x)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def predict(user_id: int) -> List[int]:\n",
    "        \"\"\"\n",
    "        Predicts ranking of movies to watch for a user.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        user_id : int\n",
    "            User's id from the data set.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        List[int]\n",
    "            List of movies ids. Best recommendations first.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def predict_score(user_id: int, movie_id: int) -> float:\n",
    "        \"\"\"\n",
    "        Predicts score for a given movie that a user would give.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        user_id : int\n",
    "            User's id from the data set.\n",
    "        movie_id : int\n",
    "            Movie's id from the data set.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        float\n",
    "            Predicted movie's score in range [0, 5]\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def predict_scores(user_id: int) -> float:\n",
    "        \"\"\"\n",
    "        Predicts scores for all the movies, that a user would give.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        user_id : int\n",
    "            User's id from the data set.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        float\n",
    "            Predicted movie's score in range [0, 5].\n",
    "        \"\"\"\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "prerequisite-essay",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 0.001\n",
    "EPOCHS = 3\n",
    "HIDDEN_SIZE = 10\n",
    "loss_func = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "stuffed-veteran",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "quantitative-gather",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Found dtype Double but expected Float",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-f44d114f60ad>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\wilk\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 245\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\wilk\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    143\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Found dtype Double but expected Float"
     ]
    }
   ],
   "source": [
    "history = {\n",
    "    'loss':[]\n",
    "}\n",
    "train_ratings, test_ratings, y_train, y_test = train_test_split(tensors,target,test_size=1000,random_state=SEED )\n",
    "\n",
    "net = ContentBaseRecommenderSystem(FLAT_SIZE,HIDDEN_SIZE)\n",
    "optimizer = optim.Adam(net.parameters(),lr=LR)\n",
    "for epoch in tqdm(range(EPOCHS)):\n",
    "    for idx, data in enumerate(train_ratings):\n",
    "        X = data\n",
    "        y = torch.tensor(y_train[idx]) \n",
    "        output = net(X)\n",
    "        loss  = loss_func(output,y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        history['loss'].append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "false-links",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brave-slovenia",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(train_ratings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eleven-honduras",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
